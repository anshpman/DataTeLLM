{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11013442,"sourceType":"datasetVersion","datasetId":6857137}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:07:49.080820Z","iopub.execute_input":"2025-04-11T18:07:49.081169Z","iopub.status.idle":"2025-04-11T18:07:49.479469Z","shell.execute_reply.started":"2025-04-11T18:07:49.081139Z","shell.execute_reply":"2025-04-11T18:07:49.478442Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/student-depression-dataset/student_depression_dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 0: Setup\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport io\nimport base64\nimport gc\nimport google.generativeai as genai\nimport pickle # <-- For saving/loading results\nfrom kaggle_secrets import UserSecretsClient\nfrom IPython.display import HTML, display, FileLink\n\nprint(\"--- Running Setup ---\")\n\n# --- Configuration ---\nDATASET_PATH = '/kaggle/input/student-depression-dataset/student_depression_dataset.csv' # Your dataset path\nOUTPUT_DIR = '/kaggle/working/output'\nRESULTS_FILE = os.path.join(OUTPUT_DIR, 'analysis_results.pkl') # File to save state\n\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nprint(f\"Output directory: {OUTPUT_DIR}\")\nprint(f\"Results file: {RESULTS_FILE}\")\n\n# --- Load API Key ---\nAPI_SECRET_LABEL = \"GOOGLE_API\" # Your secret label\ngemini_ready = False\ntry:\n    user_secrets = UserSecretsClient()\n    GEMINI_API_KEY = user_secrets.get_secret(API_SECRET_LABEL)\n    genai.configure(api_key=GEMINI_API_KEY)\n    print(\"Gemini client configured successfully.\")\n    gemini_ready = True\nexcept Exception as e:\n    print(f\"WARNING: Error loading/configuring API Key '{API_SECRET_LABEL}': {e}. LLM features disabled.\")\n\n# --- Load Data ---\ndf = None\ntry:\n    df = pd.read_csv(DATASET_PATH)\n    print(f\"Dataset loaded successfully from: {DATASET_PATH}\")\n    print(f\"Dataset shape: {df.shape}\")\nexcept Exception as e:\n    print(f\"ERROR: Failed to load dataset: {e}\")\n\n# --- Initialize and Save Initial Results ---\nanalysis_results = {}\nif df is not None:\n    analysis_results['dataset_path'] = DATASET_PATH\n    analysis_results['output_dir'] = OUTPUT_DIR\n    analysis_results['shape'] = df.shape\n    analysis_results['gemini_configured'] = gemini_ready\n    analysis_results['head'] = df.head() # Store head/tail early\n    analysis_results['tail'] = df.tail()\n    # Initialize dictionaries needed later\n    analysis_results['plot_paths'] = {}\n    analysis_results['narratives'] = {}\n    analysis_results['numerical_skewness'] = {}\n    analysis_results['anomaly_results'] = {}\n    analysis_results['clustering_results'] = {}\n    analysis_results['time_analysis_skipped'] = True # Default\n    analysis_results['time_analysis_reason'] = \"Analysis not attempted.\" # Default\n\n    try:\n        with open(RESULTS_FILE, 'wb') as f:\n            pickle.dump(analysis_results, f)\n        print(f\"Initial analysis results saved to {RESULTS_FILE}\")\n    except Exception as e:\n        print(f\"ERROR: Failed to save initial results: {e}\")\nelse:\n    print(\"ERROR: Cannot proceed without loaded DataFrame.\")\n\nprint(\"\\n--- Setup Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:08:32.454150Z","iopub.execute_input":"2025-04-11T18:08:32.454718Z","iopub.status.idle":"2025-04-11T18:08:35.759447Z","shell.execute_reply.started":"2025-04-11T18:08:32.454683Z","shell.execute_reply":"2025-04-11T18:08:35.758336Z"}},"outputs":[{"name":"stdout","text":"--- Running Setup ---\nOutput directory: /kaggle/working/output\nResults file: /kaggle/working/output/analysis_results.pkl\nGemini client configured successfully.\nDataset loaded successfully from: /kaggle/input/student-depression-dataset/student_depression_dataset.csv\nDataset shape: (27901, 18)\nInitial analysis results saved to /kaggle/working/output/analysis_results.pkl\n\n--- Setup Complete ---\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 1: Core Analysis\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport pickle\nimport io\n\nprint(\"--- Running Core Analysis ---\")\n\n# --- Load Previous Results ---\nRESULTS_FILE = '/kaggle/working/output/analysis_results.pkl' # Define again or get from results\nanalysis_results = None\nif os.path.exists(RESULTS_FILE):\n    try:\n        with open(RESULTS_FILE, 'rb') as f:\n            analysis_results = pickle.load(f)\n        print(f\"Loaded previous results from {RESULTS_FILE}\")\n    except Exception as e:\n        print(f\"ERROR: Failed to load results file '{RESULTS_FILE}': {e}. Cannot proceed.\")\n        # exit() # Or handle error\nelse:\n    print(f\"ERROR: Results file '{RESULTS_FILE}' not found. Run Setup cell first.\")\n    # exit() # Or handle error\n\n# Ensure df is loaded (it should be in memory if setup ran in same session,\n# but robustly you might pass df path via results and reload here)\n# For now, assume 'df' exists from the setup cell if analysis_results loaded.\nif analysis_results and 'df' in locals() and df is not None:\n    try:\n        print(\"Performing core analysis calculations...\")\n        # Buffer for df.info()\n        buffer = io.StringIO()\n        df.info(buf=buffer)\n        analysis_results['df_info'] = buffer.getvalue()\n\n        # Describe\n        analysis_results['summary_stats'] = df.describe(include='all')\n        print(\" - Calculated summary stats.\")\n\n        # Missing Values\n        missing_values_all = df.isnull().sum()\n        analysis_results['missing_values'] = missing_values_all[missing_values_all > 0]\n        print(f\" - Found missing values in columns: {analysis_results['missing_values'].index.tolist() if not analysis_results['missing_values'].empty else 'None'}\")\n\n        # Unique Counts\n        analysis_results['unique_counts'] = df.nunique()\n        print(\" - Calculated unique counts.\")\n\n        # --- Save Updated Results ---\n        try:\n            with open(RESULTS_FILE, 'wb') as f:\n                pickle.dump(analysis_results, f)\n            print(f\"Core analysis results saved to {RESULTS_FILE}\")\n            print(\"\\n--- Core Analysis Complete ---\")\n            print(\"Proceed to next cell (Visualizations).\")\n        except Exception as e:\n            print(f\"ERROR: Failed to save core analysis results: {e}\")\n\n    except Exception as e:\n        print(f\"ERROR during Core Analysis processing: {e}\")\nelse:\n     if not analysis_results:\n         print(\"Cannot run Core Analysis: analysis_results failed to load.\")\n     else:\n         print(\"Cannot run Core Analysis: DataFrame 'df' not found in memory.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:08:42.864125Z","iopub.execute_input":"2025-04-11T18:08:42.864623Z","iopub.status.idle":"2025-04-11T18:08:43.034531Z","shell.execute_reply.started":"2025-04-11T18:08:42.864583Z","shell.execute_reply":"2025-04-11T18:08:43.032922Z"}},"outputs":[{"name":"stdout","text":"--- Running Core Analysis ---\nLoaded previous results from /kaggle/working/output/analysis_results.pkl\nPerforming core analysis calculations...\n - Calculated summary stats.\n - Found missing values in columns: None\n - Calculated unique counts.\nCore analysis results saved to /kaggle/working/output/analysis_results.pkl\n\n--- Core Analysis Complete ---\nProceed to next cell (Visualizations).\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 2: Basic Visualizations\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport pickle\nimport gc\n\nprint(\"--- Running Basic Visualizations ---\")\n\n# --- Configuration ---\n# Ensure these match the paths used in previous cells\nOUTPUT_DIR = '/kaggle/working/output'\nRESULTS_FILE = os.path.join(OUTPUT_DIR, 'analysis_results.pkl')\n\n# --- Load Previous Results ---\nanalysis_results = None\nif os.path.exists(RESULTS_FILE):\n    try:\n        with open(RESULTS_FILE, 'rb') as f:\n            analysis_results = pickle.load(f)\n        print(f\"Loaded previous results from {RESULTS_FILE}\")\n    except Exception as e:\n        print(f\"ERROR: Failed to load results file '{RESULTS_FILE}': {e}. Cannot proceed.\")\n        # exit() or handle\nelse:\n    print(f\"ERROR: Results file '{RESULTS_FILE}' not found. Run previous cells first.\")\n    # exit() or handle\n\n# --- Check if DataFrame 'df' exists (essential) ---\n# If df wasn't saved/passed, this check fails. Robust way is to load df from path in results.\n# For now, assume 'df' is still in memory from Cell 0 if results loaded.\nif 'df' not in locals() or df is None:\n     print(\"ERROR: DataFrame 'df' not found in memory. Please re-run Cell 0 (Setup).\")\n     # exit() or handle\nelif analysis_results: # Proceed only if results were loaded\n\n    # --- Initialize dicts if they don't exist (safety check) ---\n    analysis_results.setdefault('plot_paths', {}).setdefault('histograms', {})\n    analysis_results['plot_paths'].setdefault('count_plots', {})\n    analysis_results.setdefault('numerical_skewness', {})\n\n    try: # Wrap main logic\n        # --- Numerical Histograms & Skewness ---\n        numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n        numerical_cols_to_plot = [col for col in numerical_cols if col not in ['PassengerId', 'Survived', 'Pclass']]\n        print(f\"Numerical columns for histograms: {numerical_cols_to_plot}\")\n\n        for col in numerical_cols_to_plot:\n            try:\n                fig, ax = plt.subplots(figsize=(8, 4))\n                sns.histplot(df[col].dropna(), kde=True, ax=ax)\n                ax.set_title(f'Distribution of {col}')\n                plot_filename = os.path.join(OUTPUT_DIR, f'hist_{col}.png')\n                fig.savefig(plot_filename)\n                plt.close(fig) # Close the specific figure\n\n                if os.path.exists(plot_filename):\n                    # Store relative path if desired, or keep absolute\n                    analysis_results['plot_paths']['histograms'][col] = plot_filename\n                else:\n                     print(f\" - FAILED to save hist for {col}\")\n\n                # Calculate skewness\n                analysis_results['numerical_skewness'][col] = df[col].skew()\n            except Exception as e:\n                print(f\" - Error plotting/saving hist for {col}: {e}\")\n\n        # --- Categorical Count Plots ---\n        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n        potential_numeric_cats = ['Survived', 'Pclass']\n        for col_p in potential_numeric_cats:\n             if col_p in df.columns and col_p not in categorical_cols: categorical_cols.append(col_p)\n\n        # Get unique counts from loaded results\n        unique_counts = analysis_results.get('unique_counts')\n        if unique_counts is None:\n             print(\"WARNING: Unique counts not found in loaded results. Calculating again.\")\n             unique_counts = df.nunique() # Recalculate if missing\n\n        MAX_CATEGORIES_FOR_PLOT = 25\n        categorical_cols_to_plot = sorted(list(set([c for c in categorical_cols if c in unique_counts and unique_counts[c] <= MAX_CATEGORIES_FOR_PLOT])))\n        print(f\"Categorical columns for count plots: {categorical_cols_to_plot}\")\n\n        for col_c in categorical_cols_to_plot:\n            if col_c not in df.columns: continue\n            try:\n                fig, ax = plt.subplots(figsize=(8, 4))\n                sns.countplot(data=df, x=col_c, order=df[col_c].value_counts().index, ax=ax)\n                ax.set_title(f'Count Plot for {col_c}')\n                if len(df[col_c].unique()) > 5:\n                    ax.tick_params(axis='x', rotation=45)\n                fig.tight_layout()\n                plot_filename = os.path.join(OUTPUT_DIR, f'count_{col_c}.png')\n                fig.savefig(plot_filename)\n                plt.close(fig)\n                if os.path.exists(plot_filename):\n                     analysis_results['plot_paths']['count_plots'][col_c] = plot_filename\n            except Exception as e:\n                 print(f\" - Error plotting/saving count plot for {col_c}: {e}\")\n\n        print(\"Basic visualizations successful.\")\n\n        # --- Save Updated Results ---\n        try:\n            with open(RESULTS_FILE, 'wb') as f:\n                pickle.dump(analysis_results, f)\n            print(f\"Visualization results saved to {RESULTS_FILE}\")\n            print(\"\\n--- Basic Visualizations Complete ---\")\n            print(\"Proceed to next cell (Correlation Analysis).\")\n        except Exception as e:\n            print(f\"ERROR: Failed to save visualization results: {e}\")\n\n    except Exception as e:\n        print(f\"ERROR during Basic Visualizations processing: {e}\")\n\n    gc.collect() # Garbage collect","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:08:51.752695Z","iopub.execute_input":"2025-04-11T18:08:51.753086Z","iopub.status.idle":"2025-04-11T18:08:56.058108Z","shell.execute_reply.started":"2025-04-11T18:08:51.753049Z","shell.execute_reply":"2025-04-11T18:08:56.057036Z"}},"outputs":[{"name":"stdout","text":"--- Running Basic Visualizations ---\nLoaded previous results from /kaggle/working/output/analysis_results.pkl\nNumerical columns for histograms: ['id', 'Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', 'Job Satisfaction', 'Work/Study Hours', 'Depression']\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"},{"name":"stdout","text":" - Error plotting/saving hist for Work/Study Hours: [Errno 2] No such file or directory: '/kaggle/working/output/hist_Work/Study Hours.png'\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"},{"name":"stdout","text":"Categorical columns for count plots: ['Dietary Habits', 'Family History of Mental Illness', 'Financial Stress', 'Gender', 'Have you ever had suicidal thoughts ?', 'Profession', 'Sleep Duration']\nBasic visualizations successful.\nVisualization results saved to /kaggle/working/output/analysis_results.pkl\n\n--- Basic Visualizations Complete ---\nProceed to next cell (Correlation Analysis).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Cell 3: Correlation Analysis\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport pickle\nimport gc\n\nprint(\"--- Running Correlation Analysis ---\")\n\n# --- Configuration ---\nOUTPUT_DIR = '/kaggle/working/output'\nRESULTS_FILE = os.path.join(OUTPUT_DIR, 'analysis_results.pkl')\n\n# --- Load Previous Results ---\nanalysis_results = None\nif os.path.exists(RESULTS_FILE):\n    try:\n        with open(RESULTS_FILE, 'rb') as f:\n            analysis_results = pickle.load(f)\n        print(f\"Loaded previous results from {RESULTS_FILE}\")\n    except Exception as e:\n        print(f\"ERROR: Failed to load results file '{RESULTS_FILE}': {e}. Cannot proceed.\")\n        # exit() or handle\nelse:\n    print(f\"ERROR: Results file '{RESULTS_FILE}' not found. Run previous cells first.\")\n    # exit() or handle\n\n# --- Check if DataFrame 'df' exists ---\nif 'df' not in locals() or df is None:\n     print(\"ERROR: DataFrame 'df' not found in memory. Please re-run Cell 0 (Setup).\")\n     # exit() or handle\nelif analysis_results: # Proceed only if results were loaded\n\n    # --- Initialize keys ---\n    analysis_results['correlation_skipped'] = True\n    analysis_results.setdefault('plot_paths', {}) # Ensure plot_paths exists\n    analysis_results['highly_correlated_pairs'] = []\n\n    try: # Wrap main logic\n        # --- Select Numerical Columns ---\n        # Exclude IDs, and optionally discrete categoricals like Survived/Pclass\n        cols_for_corr = [col for col in df.select_dtypes(include=np.number).columns.tolist() if col not in ['PassengerId', 'Survived']]\n\n        if len(cols_for_corr) >= 2:\n            print(f\"Calculating correlation matrix for: {cols_for_corr}\")\n\n            # --- Calculate Correlation ---\n            correlation_matrix = df[cols_for_corr].corr()\n            analysis_results['correlation_matrix'] = correlation_matrix # Store matrix if needed later\n            analysis_results['correlation_skipped'] = False\n\n            # --- Generate Heatmap ---\n            try:\n                fig, ax = plt.subplots(figsize=(10, 8))\n                sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, ax=ax)\n                ax.set_title('Correlation Matrix')\n                fig.tight_layout()\n                plot_filename = os.path.join(OUTPUT_DIR, 'correlation_heatmap.png')\n                fig.savefig(plot_filename)\n                plt.close(fig) # Close figure\n\n                if os.path.exists(plot_filename):\n                    analysis_results['plot_paths']['heatmap'] = plot_filename\n                    print(\" - Saved correlation heatmap.\")\n                else:\n                     print(\" - FAILED to save correlation heatmap.\")\n            except Exception as e:\n                 print(f\" - Error generating/saving heatmap: {e}\")\n\n            # --- Identify Highly Correlated Pairs ---\n            CORR_THRESHOLD = 0.4\n            print(f\" - Identifying pairs with absolute correlation > {CORR_THRESHOLD}\")\n            # Unstack matrix, remove self-correlation, filter by threshold\n            corr_unstacked = correlation_matrix.unstack()\n            strong_pairs_series = corr_unstacked[(abs(corr_unstacked) > CORR_THRESHOLD) & (corr_unstacked != 1.0)]\n\n            highly_corr_pairs_list = []\n            seen_pairs = set()\n            for (var1, var2), corr_value in strong_pairs_series.items():\n                pair = tuple(sorted((var1, var2))) # Ensure ('A','B') is same as ('B','A')\n                if pair not in seen_pairs:\n                    highly_corr_pairs_list.append(((var1, var2), corr_value))\n                    seen_pairs.add(pair)\n\n            analysis_results['highly_correlated_pairs'] = highly_corr_pairs_list\n            if highly_corr_pairs_list:\n                 print(f\" - Found pairs: {highly_corr_pairs_list}\")\n            else:\n                 print(\" - No pairs found above threshold.\")\n\n        else:\n            print(\"Skipping correlation analysis: Need at least 2 numerical columns.\")\n            analysis_results['correlation_skipped'] = True\n\n        print(\"Correlation analysis successful.\")\n\n        # --- Save Updated Results ---\n        try:\n            with open(RESULTS_FILE, 'wb') as f:\n                pickle.dump(analysis_results, f)\n            print(f\"Correlation results saved to {RESULTS_FILE}\")\n            print(\"\\n--- Correlation Analysis Complete ---\")\n            print(\"Proceed to next cell (Anomaly Detection).\")\n        except Exception as e:\n            print(f\"ERROR: Failed to save correlation results: {e}\")\n\n    except Exception as e:\n        print(f\"ERROR during Correlation Analysis processing: {e}\")\n\n    gc.collect() # Garbage collect","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:09:09.770129Z","iopub.execute_input":"2025-04-11T18:09:09.770520Z","iopub.status.idle":"2025-04-11T18:09:10.416583Z","shell.execute_reply.started":"2025-04-11T18:09:09.770493Z","shell.execute_reply":"2025-04-11T18:09:10.415286Z"}},"outputs":[{"name":"stdout","text":"--- Running Correlation Analysis ---\nLoaded previous results from /kaggle/working/output/analysis_results.pkl\nCalculating correlation matrix for: ['id', 'Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', 'Job Satisfaction', 'Work/Study Hours', 'Depression']\n - Saved correlation heatmap.\n - Identifying pairs with absolute correlation > 0.4\n - Found pairs: [(('Academic Pressure', 'Depression'), 0.474834943980666), (('Work Pressure', 'Job Satisfaction'), 0.7706521656642141)]\nCorrelation analysis successful.\nCorrelation results saved to /kaggle/working/output/analysis_results.pkl\n\n--- Correlation Analysis Complete ---\nProceed to next cell (Anomaly Detection).\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Cell 4: Anomaly Detection\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport pickle\nimport gc\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.impute import SimpleImputer\n\nprint(\"--- Running Anomaly Detection (Isolation Forest) ---\")\n\n# --- Configuration ---\nOUTPUT_DIR = '/kaggle/working/output'\nRESULTS_FILE = os.path.join(OUTPUT_DIR, 'analysis_results.pkl')\n\n# --- Load Previous Results ---\nanalysis_results = None\nif os.path.exists(RESULTS_FILE):\n    try:\n        with open(RESULTS_FILE, 'rb') as f:\n            analysis_results = pickle.load(f)\n        print(f\"Loaded previous results from {RESULTS_FILE}\")\n    except Exception as e:\n        print(f\"ERROR: Failed to load results file '{RESULTS_FILE}': {e}. Cannot proceed.\")\n        # exit() or handle\nelse:\n    print(f\"ERROR: Results file '{RESULTS_FILE}' not found. Run previous cells first.\")\n    # exit() or handle\n\n# --- Check if DataFrame 'df' exists ---\nif 'df' not in locals() or df is None:\n     print(\"ERROR: DataFrame 'df' not found in memory. Please re-run Cell 0 (Setup).\")\n     # exit() or handle\nelif analysis_results: # Proceed only if results were loaded\n\n    # --- Initialize keys ---\n    analysis_results['anomaly_skipped'] = True\n    analysis_results.setdefault('anomaly_results', {}) # Ensure nested dict exists\n    anomaly_features = ['Age', 'SibSp', 'Parch', 'Fare'] # Features for anomaly detection\n    analysis_results['anomaly_results']['features_used'] = anomaly_features\n\n    try: # Wrap main logic\n        # Select data and handle potential missing columns\n        available_features = [f for f in anomaly_features if f in df.columns]\n        if len(available_features) < 1:\n             print(\"Skipping anomaly detection: None of the specified features exist in the DataFrame.\")\n        else:\n            print(f\"Using features for anomaly detection: {available_features}\")\n            df_anomaly = df[available_features].copy()\n\n            # Check if data is purely NaN before imputing\n            if not df_anomaly.empty and df_anomaly.notna().any().any():\n                # Impute missing values FOR THE MODEL ONLY\n                imputer_ad = SimpleImputer(strategy='median')\n                df_anomaly_imputed = imputer_ad.fit_transform(df_anomaly)\n                # Keep as numpy array for IsolationForest, avoid DataFrame conversion if not needed\n                # df_anomaly_imputed_df = pd.DataFrame(df_anomaly_imputed, columns=available_features, index=df_anomaly.index)\n\n                imputed_cols_msg = [f\"{col}({imputer_ad.statistics_[available_features.index(col)]:.2f})\" for col in available_features if df_anomaly[col].isnull().any()]\n                if imputed_cols_msg:\n                     print(f\" - Imputed NaNs for anomaly detection in: {', '.join(imputed_cols_msg)}.\")\n\n                # Fit Isolation Forest\n                iso_forest = IsolationForest(contamination='auto', random_state=42)\n                predictions = iso_forest.fit_predict(df_anomaly_imputed) # Use imputed numpy array\n\n                # Store results\n                analysis_results['anomaly_results']['predictions'] = predictions # Optional: store predictions\n                analysis_results['anomaly_results']['count'] = np.sum(predictions == -1)\n                analysis_results['anomaly_results']['percentage'] = (np.mean(predictions == -1) * 100)\n                analysis_results['anomaly_skipped'] = False\n\n                print(f\"Anomaly detection successful.\")\n                print(f\" - Found {analysis_results['anomaly_results']['count']} potential anomalies ({analysis_results['anomaly_results']['percentage']:.2f}%).\")\n                # del df_anomaly_imputed_df # Clean up if created\n            else:\n                print(\"Skipping anomaly detection: No suitable features or only NaN values after selection.\")\n\n    except Exception as e:\n        print(f\"ERROR during Anomaly Detection processing: {e}\")\n\n    # --- Save Updated Results ---\n    if analysis_results: # Ensure results exist before saving\n        try:\n            with open(RESULTS_FILE, 'wb') as f:\n                pickle.dump(analysis_results, f)\n            print(f\"Anomaly detection results saved to {RESULTS_FILE}\")\n            print(\"\\n--- Anomaly Detection Complete ---\")\n            print(\"Proceed to next cell (Clustering Exploration).\")\n        except Exception as e:\n            print(f\"ERROR: Failed to save anomaly detection results: {e}\")\n\n    gc.collect() # Garbage collect","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:09:19.795044Z","iopub.execute_input":"2025-04-11T18:09:19.795447Z","iopub.status.idle":"2025-04-11T18:09:21.514904Z","shell.execute_reply.started":"2025-04-11T18:09:19.795413Z","shell.execute_reply":"2025-04-11T18:09:21.513744Z"}},"outputs":[{"name":"stdout","text":"--- Running Anomaly Detection (Isolation Forest) ---\nLoaded previous results from /kaggle/working/output/analysis_results.pkl\nUsing features for anomaly detection: ['Age']\nAnomaly detection successful.\n - Found 23510 potential anomalies (84.26%).\nAnomaly detection results saved to /kaggle/working/output/analysis_results.pkl\n\n--- Anomaly Detection Complete ---\nProceed to next cell (Clustering Exploration).\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Cell 5: Clustering Exploration\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport pickle\nimport gc\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.decomposition import PCA\n\nprint(\"--- Running Clustering Exploration (K-Means) ---\")\n\n# --- Configuration ---\nOUTPUT_DIR = '/kaggle/working/output'\nRESULTS_FILE = os.path.join(OUTPUT_DIR, 'analysis_results.pkl')\n\n# --- Load Previous Results ---\nanalysis_results = None\nif os.path.exists(RESULTS_FILE):\n    try:\n        with open(RESULTS_FILE, 'rb') as f:\n            analysis_results = pickle.load(f)\n        print(f\"Loaded previous results from {RESULTS_FILE}\")\n    except Exception as e:\n        print(f\"ERROR: Failed to load results file '{RESULTS_FILE}': {e}. Cannot proceed.\")\n        # exit() or handle\nelse:\n    print(f\"ERROR: Results file '{RESULTS_FILE}' not found. Run previous cells first.\")\n    # exit() or handle\n\n# --- Check if DataFrame 'df' exists ---\nif 'df' not in locals() or df is None:\n     print(\"ERROR: DataFrame 'df' not found in memory. Please re-run Cell 0 (Setup).\")\n     # exit() or handle\nelif analysis_results: # Proceed only if results were loaded\n\n    # --- Initialize keys ---\n    analysis_results['clustering_skipped'] = True\n    analysis_results.setdefault('clustering_results', {}) # Ensure nested dict exists\n    analysis_results['plot_paths'].setdefault('clustering_pca', None) # Specific key for plot\n\n    clustering_features = ['Age', 'Fare', 'SibSp', 'Parch'] # Features to use\n    n_clusters_fixed = 4 # Fixed number of clusters for this example\n    analysis_results['clustering_results']['n_clusters'] = n_clusters_fixed\n    analysis_results['clustering_results']['features_used'] = clustering_features # Store features used\n\n    try: # Wrap main logic\n        # Select data and check validity\n        available_features = [f for f in clustering_features if f in df.columns]\n        if len(available_features) < 2:\n            print(\"Skipping clustering: Not enough specified features exist in the DataFrame.\")\n            analysis_results['clustering_reason'] = \"Not Applicable: Insufficient features.\"\n        else:\n            df_cluster_orig = df[available_features].copy()\n            # Check if data is purely NaN before imputing/fitting\n            if not df_cluster_orig.empty and df_cluster_orig.notna().any().any():\n                print(f\"Using features for clustering: {available_features}\")\n\n                # --- Preprocessing ---\n                imputer_cl = SimpleImputer(strategy='median')\n                df_cluster_imputed = imputer_cl.fit_transform(df_cluster_orig)\n                df_cluster_imputed_df = pd.DataFrame(df_cluster_imputed, columns=available_features, index=df_cluster_orig.index)\n                print(\" - Imputed missing values for clustering using median.\")\n\n                scaler = StandardScaler()\n                df_cluster_scaled = scaler.fit_transform(df_cluster_imputed_df)\n                print(\" - Scaled features using StandardScaler.\")\n\n                # --- Run K-Means ---\n                kmeans = KMeans(n_clusters=n_clusters_fixed, n_init='auto', random_state=42)\n                cluster_labels = kmeans.fit_predict(df_cluster_scaled)\n                analysis_results['clustering_results']['labels'] = cluster_labels\n                df_cluster_imputed_df['Cluster'] = cluster_labels # Add labels for analysis\n                print(f\" - K-Means clustering performed with K={n_clusters_fixed}.\")\n\n                # --- Analyze Clusters ---\n                cluster_summary = df_cluster_imputed_df.groupby('Cluster')[available_features].mean().round(2)\n                analysis_results['clustering_results']['summary_stats'] = cluster_summary\n                print(\" - Calculated cluster characteristics (mean values):\")\n                print(cluster_summary)\n\n                # --- Visualize Clusters (PCA) ---\n                try:\n                     pca = PCA(n_components=2, random_state=42)\n                     df_cluster_pca = pca.fit_transform(df_cluster_scaled)\n                     print(f\" - PCA performed for visualization. Explained variance ratio: {pca.explained_variance_ratio_}\")\n\n                     fig, ax = plt.subplots(figsize=(10, 7))\n                     sns.scatterplot(x=df_cluster_pca[:, 0], y=df_cluster_pca[:, 1], hue=cluster_labels, palette='viridis', s=50, alpha=0.7, ax=ax)\n                     ax.set_title(f'Data Points Clustered into {n_clusters_fixed} Groups (PCA)')\n                     ax.set_xlabel('Principal Component 1')\n                     ax.set_ylabel('Principal Component 2')\n                     ax.legend(title='Cluster')\n                     ax.grid(True, linestyle='--', alpha=0.5)\n                     fig.tight_layout()\n                     plot_filename = os.path.join(OUTPUT_DIR, 'clustering_pca_scatter.png')\n                     fig.savefig(plot_filename)\n                     plt.close(fig)\n\n                     if os.path.exists(plot_filename):\n                          analysis_results['plot_paths']['clustering_pca'] = plot_filename\n                          print(\" - Saved cluster PCA scatter plot.\")\n                     else: print(\" - FAILED to save cluster PCA scatter plot.\")\n                except Exception as viz_e:\n                     print(f\" - ERROR during clustering visualization: {viz_e}\")\n\n                analysis_results['clustering_skipped'] = False\n                print(\"Clustering exploration successful.\")\n                # Clean up intermediate objects\n                del df_cluster_scaled, df_cluster_pca, cluster_labels, df_cluster_imputed_df\n            else:\n                print(\"Skipping clustering: No suitable features or only NaN values after selection.\")\n                analysis_results['clustering_reason'] = \"Not Applicable: Insufficient data after cleaning.\"\n\n    except Exception as e:\n        print(f\"ERROR during Clustering Exploration processing: {e}\")\n\n    # Clean up original copy\n    if 'df_cluster_orig' in locals(): del df_cluster_orig\n    gc.collect()\n\n    # --- Save Updated Results ---\n    if analysis_results:\n        try:\n            with open(RESULTS_FILE, 'wb') as f:\n                pickle.dump(analysis_results, f)\n            print(f\"Clustering results saved to {RESULTS_FILE}\")\n            print(\"\\n--- Clustering Exploration Complete ---\")\n            print(\"Proceed to next cell (Time Series Check / LLM Generation).\")\n        except Exception as e:\n            print(f\"ERROR: Failed to save clustering results: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:09:32.922190Z","iopub.execute_input":"2025-04-11T18:09:32.922704Z","iopub.status.idle":"2025-04-11T18:09:33.215566Z","shell.execute_reply.started":"2025-04-11T18:09:32.922664Z","shell.execute_reply":"2025-04-11T18:09:33.213955Z"}},"outputs":[{"name":"stdout","text":"--- Running Clustering Exploration (K-Means) ---\nLoaded previous results from /kaggle/working/output/analysis_results.pkl\nSkipping clustering: Not enough specified features exist in the DataFrame.\nClustering results saved to /kaggle/working/output/analysis_results.pkl\n\n--- Clustering Exploration Complete ---\nProceed to next cell (Time Series Check / LLM Generation).\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Cell 6: Time Series Check & Analysis\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport pickle\nimport gc\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n# Note: Assumes necessary libraries (pandas, numpy, statsmodels, matplotlib) are loaded\n\nprint(\"--- Running Time Series Check & Analysis ---\")\n\n# --- Configuration ---\nOUTPUT_DIR = '/kaggle/working/output'\nRESULTS_FILE = os.path.join(OUTPUT_DIR, 'analysis_results.pkl')\n\n# --- Load Previous Results ---\nanalysis_results = None\nif os.path.exists(RESULTS_FILE):\n    try:\n        with open(RESULTS_FILE, 'rb') as f:\n            analysis_results = pickle.load(f)\n        print(f\"Loaded previous results from {RESULTS_FILE}\")\n    except Exception as e:\n        print(f\"ERROR: Failed to load results file '{RESULTS_FILE}': {e}. Cannot proceed.\")\n        # exit() or handle\nelse:\n    print(f\"ERROR: Results file '{RESULTS_FILE}' not found. Run previous cells first.\")\n    # exit() or handle\n\n# --- Check if DataFrame 'df' exists ---\nif 'df' not in locals() or df is None:\n     print(\"ERROR: DataFrame 'df' not found in memory. Please re-run Cell 0 (Setup).\")\n     # exit() or handle\nelif analysis_results: # Proceed only if results were loaded\n\n    # --- Redefine Helper/Analysis Functions needed in this cell ---\n    # Redefining here makes the cell more self-contained if run independently later\n    def find_time_column(df):\n        \"\"\"Attempts to find a likely time/date/sequence column.\"\"\"\n        print(\"\\n--- Checking for Time Series Column ---\")\n        for col in df.select_dtypes(include=['datetime64']).columns: print(f\" - Found datetime column: {col}\"); return col\n        time_keywords = ['date', 'time', 'timestamp', 'period', 'year', 'month', 'day', 'dt']\n        for col in df.columns:\n            if any(keyword in col.lower() for keyword in time_keywords):\n                try:\n                    if pd.to_datetime(df[col], errors='coerce').notna().mean() > 0.5: print(f\" - Found likely time column by name: {col}\"); return col\n                except Exception: continue\n        if isinstance(df.index, pd.DatetimeIndex) and not isinstance(df.index, pd.RangeIndex): print(f\" - Found DatetimeIndex. Consider resetting index.\"); return None\n        print(\" - No obvious time/date column found.\"); return None\n\n    def run_time_analysis(df_original, time_col_name, results, out_dir):\n        \"\"\"Performs basic time series analysis if a time column is found.\"\"\"\n        print(f\"\\n--- Running Time Series Analysis on column: {time_col_name} ---\")\n        results['time_analysis_skipped'] = True; results['plot_paths'].setdefault('time_series', {}); results['narratives'].setdefault('time_series_description',\"Skipped/Failed.\"); results['narratives'].setdefault('time_series_suggestions',\"N/A.\"); results['time_analysis_reason']=\"Analysis started.\"\n        target_col = None;\n        try:\n            df_ts = df_original.copy(); # Use df_ts locally\n            try:\n                df_ts[time_col_name]=pd.to_datetime(df_ts[time_col_name], errors='coerce'); dropped=len(df_ts); df_ts.dropna(subset=[time_col_name], inplace=True); dropped=dropped-len(df_ts);\n                if dropped > 0: print(f\" - Warn: Dropped {dropped} rows with bad dates.\");\n                if len(df_ts) < 12: print(f\" - Skip: Not enough valid time points ({len(df_ts)}).\"); results['time_analysis_reason'] = \"NA: Insufficient data.\"; return results\n                df_ts=df_ts.sort_values(by=time_col_name).set_index(time_col_name); print(f\" - Set {time_col_name} as index.\")\n            except Exception as e: print(f\"ERROR processing time column {time_col_name}: {e}\"); results['time_analysis_reason'] = f\"Failed: Error processing column.\"; return results\n\n            numeric_cols=df_ts.select_dtypes(include=np.number).columns; cols_exclude=['PassengerId','Survived','Pclass'];\n            for col in numeric_cols:\n                 if col not in cols_exclude: target_col=col; break\n            if target_col is None: print(\"Skip TS: No suitable numerical column.\"); results['time_analysis_reason'] = \"NA: No numerical column.\"; return results\n\n            print(f\" - Analyzing '{target_col}' over time.\"); ts_data=df_ts[target_col].dropna()\n            if len(ts_data) < 12: print(f\"Skip plots: Not enough data points ({len(ts_data)}) in '{target_col}'.\"); results['time_analysis_reason'] = f\"NA: Insufficient data in {target_col}.\"; return results\n\n            # Trend Plot\n            try:\n                fig, ax=plt.subplots(figsize=(12, 5)); ts_data.plot(ax=ax, label=target_col, title=f'Trend of {target_col}');\n                try: \n                    window=max(1, min(len(ts_data)//10, 50));\n                    if len(ts_data)>=window: ts_data.rolling(window=window).mean().plot(ax=ax, label=f'Rolling Mean ({window})', linestyle='--')\n                except: pass # Ignore rolling mean error\n                ax.legend(); ax.grid(True, alpha=0.5); fig.tight_layout(); fname=os.path.join(out_dir, f'trend_{target_col}.png'); fig.savefig(fname); plt.close(fig);\n                if os.path.exists(fname): results['plot_paths']['time_series'][f'trend_{target_col}'] = fname; print(\" - Saved trend plot.\")\n            except Exception as e: print(f\" - Error trend plot {target_col}: {e}\")\n\n            # Decomposition\n            try:\n                period = 12; # Example period\n                if len(ts_data) >= 2*period:\n                    print(f\" - Decomposing (period={period})...\"); decomp = seasonal_decompose(ts_data, model='additive', period=period, extrapolate_trend='freq'); fig_d = decomp.plot(); fig_d.set_size_inches(10, 8); plt.suptitle(f\"Decomposition {target_col}\", y=1.02); plt.tight_layout(rect=[0,0.03,1,0.98]); fname_d=os.path.join(out_dir, f'decomp_{target_col}.png'); fig_d.savefig(fname_d); plt.close(fig_d);\n                    if os.path.exists(fname_d): results['plot_paths']['time_series'][f'decomp_{target_col}'] = fname_d; print(\" - Saved decomp plot.\")\n                    results['time_analysis_results'] = {'target_col': target_col, 'period_used': period} # Store results\n                else: print(f\" - Skip decomp: Need {2*period} points, have {len(ts_data)}.\")\n            except Exception as e: print(f\" - Error decomposition {target_col}: {e}\")\n\n            results['time_analysis_skipped']=False; results['time_analysis_reason']=\"Analysis performed.\"; print(\"Time series analysis successful.\")\n        except Exception as e: print(f\"ERROR during Time Series Analysis Section: {e}\"); results['time_analysis_reason']=f\"Failed: {type(e).__name__}.\"\n        gc.collect(); return results\n\n\n    # --- Main Logic for this Cell ---\n    try:\n        # Find time column\n        time_col = find_time_column(df) # Pass the DataFrame loaded in Cell 0\n\n        if time_col:\n            # Run the analysis function if column found\n            analysis_results = run_time_analysis(df, time_col, analysis_results, OUTPUT_DIR)\n        else:\n            # Update skipped reason if no column found\n            analysis_results['time_analysis_skipped'] = True\n            analysis_results['time_analysis_reason'] = \"Not Applicable: No suitable time/sequence column identified.\"\n            print(\"Time series analysis skipped as no suitable column was found.\")\n\n        # --- Save Updated Results ---\n        try:\n            with open(RESULTS_FILE, 'wb') as f:\n                pickle.dump(analysis_results, f)\n            print(f\"Time series check results saved to {RESULTS_FILE}\")\n            print(\"\\n--- Time Series Check / Analysis Complete ---\")\n            print(\"Proceed to next cell (LLM Generation).\")\n        except Exception as e:\n            print(f\"ERROR: Failed to save time series check results: {e}\")\n\n    except Exception as e:\n        print(f\"ERROR during Time Series Check processing: {e}\")\n\nelse:\n     print(\"Cannot run Time Series Check: analysis_results failed to load or df is missing.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:09:53.928396Z","iopub.execute_input":"2025-04-11T18:09:53.928749Z","iopub.status.idle":"2025-04-11T18:09:54.167247Z","shell.execute_reply.started":"2025-04-11T18:09:53.928720Z","shell.execute_reply":"2025-04-11T18:09:54.166279Z"}},"outputs":[{"name":"stdout","text":"--- Running Time Series Check & Analysis ---\nLoaded previous results from /kaggle/working/output/analysis_results.pkl\n\n--- Checking for Time Series Column ---\n - No obvious time/date column found.\nTime series analysis skipped as no suitable column was found.\nTime series check results saved to /kaggle/working/output/analysis_results.pkl\n\n--- Time Series Check / Analysis Complete ---\nProceed to next cell (LLM Generation).\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Cell 7: LLM Narrative & Suggestion Generation\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport pickle\nimport gc\nimport google.generativeai as genai\n# Note: Other imports might be needed if running stand-alone, but assume df exists\n\nprint(\"--- Running LLM Narrative & Suggestion Generation ---\")\n\n# --- Configuration ---\nOUTPUT_DIR = '/kaggle/working/output'\nRESULTS_FILE = os.path.join(OUTPUT_DIR, 'analysis_results.pkl')\n\n# --- Load Previous Results ---\nanalysis_results = None\nif os.path.exists(RESULTS_FILE):\n    try:\n        with open(RESULTS_FILE, 'rb') as f:\n            analysis_results = pickle.load(f)\n        print(f\"Loaded previous results from {RESULTS_FILE}\")\n    except Exception as e:\n        print(f\"ERROR: Failed to load results file '{RESULTS_FILE}': {e}. Cannot proceed.\")\n        # exit() or handle\nelse:\n    print(f\"ERROR: Results file '{RESULTS_FILE}' not found. Run previous cells first.\")\n    # exit() or handle\n\n# --- Check if DataFrame 'df' exists ---\nif 'df' not in locals() or df is None:\n     print(\"ERROR: DataFrame 'df' not found in memory. Please re-run Cell 0 (Setup).\")\n     # exit() or handle\nelif analysis_results: # Proceed only if results were loaded\n\n    gemini_ready = analysis_results.get('gemini_configured', False)\n    print(f\"Gemini Readiness Check: {gemini_ready}\")\n\n    # --- Redefine Helper Function ---\n    def get_gemini_narrative(prompt, gemini_ready, model_name=\"models/gemini-1.5-flash-latest\"):\n        \"\"\"Generates narrative using Gemini, handles errors.\"\"\"\n        if not gemini_ready: return \"LLM processing skipped: Not configured.\"\n        try:\n            model = genai.GenerativeModel(model_name); response=model.generate_content(prompt, generation_config=genai.types.GenerationConfig(temperature=0.7), request_options={'timeout': 120});\n            if response.candidates and hasattr(response.candidates[0], 'content') and hasattr(response.candidates[0].content, 'parts') and len(response.candidates[0].content.parts) > 0:\n                 generated_text = response.candidates[0].content.parts[0].text; return generated_text.strip() if generated_text else \"Narrative generation failed (empty text).\"\n            else: feedback = getattr(response, 'prompt_feedback', 'N/A'); finish_reason = getattr(response.candidates[0], 'finish_reason', 'N/A') if response.candidates else 'N/A'; print(f\"WARN: LLM response structure issue. Finish Reason: {finish_reason}. Feedback: {feedback}\"); return \"Narrative generation failed (unexpected response).\"\n        except Exception as e: print(f\"ERROR during Gemini API call ({model_name}): {e}\"); return f\"Narrative generation failed due to API error: {type(e).__name__}\"\n\n    # --- Redefine LLM Generation Function (with internal try-except) ---\n    def run_llm_generation(df, results, gemini_ready):\n        print(\"\\n--- Running LLM Narrative & Suggestion Generation ---\")\n        if not gemini_ready: print(\"Skipping ALL LLM Generation.\"); narr_keys=['overview','statistics','nuances','visualizations','correlation','anomaly_description','clustering_description','domain_insights','time_series_description']; sugg_keys=['nuances_suggestions','viz_suggestions','corr_suggestions','clustering_suggestions','risk_identification','time_series_suggestions']; [results['narratives'].setdefault(key, \"LLM Skipped.\") for key in narr_keys+sugg_keys]; return results\n\n        print(\"Generating main narratives & suggestions...\"); results['narratives'] = {}\n        narr_keys=['overview','statistics','nuances','visualizations','correlation','anomaly_description','clustering_description','domain_insights','time_series_description']; sugg_keys=['nuances_suggestions','viz_suggestions','corr_suggestions','clustering_suggestions','risk_identification','time_series_suggestions']; [results['narratives'].setdefault(key, \"Gen Pending...\") for key in narr_keys+sugg_keys]\n\n        # --- Generate Narratives (WITH internal try-except for robustness) ---\n        print(\" - Generating Overview Narrative...\")\n        try: shape=results.get('shape','N/A'); head_str=results.get('head', pd.DataFrame()).to_string(); prompt=f\"Dataset Shape: {shape}. First 5 Rows:\\n{head_str}\\n\\nWrite 2-3 sentence intro paragraph (mention Sex, Age, Pclass).\"; results['narratives']['overview'] = get_gemini_narrative(prompt, gemini_ready)\n        except Exception as e: results['narratives']['overview'] = f\"Error: {e}\"\n\n        print(\" - Generating Statistics Narrative...\")\n        try: stats_str=results.get('summary_stats',pd.DataFrame()).to_string(); prompt=f\"Stats:\\n{stats_str}\\n\\nWrite 3-5 sentence summary. Mention Age/Fare (skew?), Sex/Pclass/Embarked (top categories).\"; results['narratives']['statistics'] = get_gemini_narrative(prompt, gemini_ready)\n        except Exception as e: results['narratives']['statistics'] = f\"Error: {e}\"\n\n        print(\" - Generating Nuances Narrative...\")\n        try:\n            missing_sr=results.get('missing_values'); total_rows=results.get('shape',(0,0))[0]; missing_str=\"None.\"; missing_summary=\"\"\n            if missing_sr is not None and not missing_sr.empty: missing_summary_list=[f\"{i} ({((v/total_rows)*100):.1f}%)\" for i,v in missing_sr.items()]; missing_summary=\", \".join(missing_summary_list); missing_str=\"\\n\".join([f\"- {i}: {v} ({((v/total_rows)*100):.1f}%)\" for i,v in missing_sr.items()])\n            unique_sr=results.get('unique_counts',pd.Series()); unique_str=unique_sr.to_string() if unique_sr is not None else \"N/A\"; prompt=f\"{total_rows} rows.\\nMissing:\\n{missing_str}\\nUnique:\\n{unique_str}\\n\\nWrite 3-5 sentence quality summary. Highlight missing (Cabin, Age), identifiers (PassengerId), categoricals (Pclass, Sex).\"; results['narratives']['nuances']=get_gemini_narrative(prompt, gemini_ready)\n        except Exception as e: results['narratives']['nuances']=f\"Error: {e}\"\n\n        print(\" - Generating Visualizations Narrative...\")\n        try:\n            skew_data=results.get('numerical_skewness',{}); skew_str=\", \".join([f\"{k}: {v:.2f}\" for k,v in skew_data.items()]); hist_keys=list(results.get('plot_paths',{}).get('histograms',{})); count_keys=list(results.get('plot_paths',{}).get('count_plots',{}))\n            prompt=f\"Histograms: {hist_keys}. Skew: {skew_str}. Count plots: {count_keys}. Write 3-5 sentence summary of distribution shapes (skew) & dominant categories.\"\n            results['narratives']['visualizations'] = get_gemini_narrative(prompt, gemini_ready)\n        except Exception as e: results['narratives']['visualizations'] = f\"Error: {e}\"\n\n        print(\" - Generating Correlation Narrative...\")\n        try:\n            corr_pairs=results.get('highly_correlated_pairs',[]); narrative_corr=\"Skipped/Failed.\"\n            if not results.get('correlation_skipped') and corr_pairs: corr_str=\", \".join([f\"{p[0]} ({p[1]:.2f})\" for p in corr_pairs]); prompt=f\"Notable correlations (abs>0.4): {corr_str}. Write 2-4 sentence explanation (e.g., Pclass/Fare).\"; narrative_corr=get_gemini_narrative(prompt, gemini_ready)\n            elif not results.get('correlation_skipped'): narrative_corr=\"No significant correlations (>0.4) identified.\"\n            else: narrative_corr=\"Correlation analysis skipped.\"\n            results['narratives']['correlation'] = narrative_corr\n        except Exception as e: results['narratives']['correlation'] = f\"Error: {e}\"\n\n        print(\" - Generating Anomaly Description Narrative...\")\n        try:\n            anomaly_features = results.get('anomaly_results',{}).get('features_used',['N/A'])\n            if not results.get('anomaly_skipped'): anomaly_count=results['anomaly_results']['count']; anomaly_perc=results['anomaly_results']['percentage']; prompt=f\"Isolation Forest found {anomaly_count} ({anomaly_perc:.2f}%) potential anomalies using {anomaly_features}. Explain briefly what this means (1-2 sentences).\"; results['narratives']['anomaly_description'] = get_gemini_narrative(prompt, gemini_ready)\n            else: results['narratives']['anomaly_description'] = \"Anomaly detection skipped.\"\n        except Exception as e: results['narratives']['anomaly_description'] = f\"Error: {e}\"\n\n        print(\" - Generating Clustering Description Narrative...\")\n        try:\n            clustering_features = results.get('clustering_results',{}).get('features_used',['N/A'])\n            if not results.get('clustering_skipped'): k=results['clustering_results']['n_clusters']; cluster_summary_str=results['clustering_results']['summary_stats'].to_string(); prompt=f\"K={k} clusters found using {clustering_features}. Cluster Means:\\n{cluster_summary_str}\\n\\nWrite paragraph describing key characteristics differentiating these {k} clusters based on means (3-5 sentences).\"; results['narratives']['clustering_description'] = get_gemini_narrative(prompt, gemini_ready)\n            else: results['narratives']['clustering_description'] = \"Clustering analysis skipped.\"\n        except Exception as e: results['narratives']['clustering_description'] = f\"Error: {e}\"\n\n        print(\" - Generating Domain Insights Narrative...\")\n        try: column_names = df.columns.tolist(); dtypes_str = df.dtypes.to_string(); prompt=f\"Based ONLY on columns: {column_names} & types:\\n{dtypes_str}\\nWhat is the likely domain (e.g., travel, health)? What are 1-2 typical analysis goals or advanced analyses? Be brief (2-3 sentences) & state this is speculative.\"; results['narratives']['domain_insights'] = get_gemini_narrative(prompt, gemini_ready)\n        except Exception as e: results['narratives']['domain_insights'] = f\"Error: {e}\"\n\n        print(\" - Generating Time Series Narrative...\")\n        try:\n            if not results.get('time_analysis_skipped'):\n                ts_plots=list(results.get('plot_paths',{}).get('time_series',{})); ts_target=results.get('time_analysis_results',{}).get('target_col','N/A'); ts_period=results.get('time_analysis_results',{}).get('period_used','N/A')\n                context=f\"Time series analysis performed on '{ts_target}'. Plots generated: {ts_plots}. Decomposition assumed period={ts_period}.\"\n                prompt=f\"Context: [{context}]. Write brief summary of analysis & observed trends/patterns.\"\n                results['narratives']['time_series_description'] = get_gemini_narrative(prompt, gemini_ready)\n            else: results['narratives']['time_series_description'] = results.get('time_analysis_reason', \"TS analysis skipped/NA.\")\n        except Exception as e: results['narratives']['time_series_description'] = f\"Error: {e}\"\n\n        # --- Generate Suggestions & Risk ID ---\n        print(\"\\nGenerating suggestions & risk ID...\")\n        try: prompt=f\"Findings: [Missing data: {missing_summary}. Identifiers: PassengerId, Name. Categoricals: Survived, Pclass, Sex, Embarked.]. Implications/next steps for analysis/modeling? (1-2 points)\"; results['narratives']['nuances_suggestions'] = get_gemini_narrative(prompt, gemini_ready)\n        except Exception as e: results['narratives']['nuances_suggestions'] = f\"Error: {e}\"\n        try: prompt=f\"Findings: [Skewness: {skew_str}. Dominant categories in: {count_keys}.]. Implications of distributions/dominance for feature engineering/modeling? (1-2 points)\"; results['narratives']['viz_suggestions'] = get_gemini_narrative(prompt, gemini_ready)\n        except Exception as e: results['narratives']['viz_suggestions'] = f\"Error: {e}\"\n        try:\n             if not results.get('correlation_skipped') and 'corr_str' in locals() and corr_str: context=f\"Correlations: {corr_str}.\"; prompt=f\"Findings: [{context}]. What might these signify? Next steps for exploration?\"; results['narratives']['corr_suggestions'] = get_gemini_narrative(prompt, gemini_ready)\n             else: results['narratives']['corr_suggestions'] = \"N/A.\"\n        except Exception as e: results['narratives']['corr_suggestions'] = f\"Error: {e}\"\n        try:\n            if not results.get('clustering_skipped'): cluster_summary_str=results['clustering_results']['summary_stats'].to_string(); k=results['clustering_results']['n_clusters']; prompt=f\"Findings: [{k} clusters found with characteristics:\\n{cluster_summary_str}]. What might these segments represent (e.g., Titanic context)? Potential next steps?\"; results['narratives']['clustering_suggestions'] = get_gemini_narrative(prompt, gemini_ready)\n            else: results['narratives']['clustering_suggestions'] = \"N/A.\"\n        except Exception as e: results['narratives']['clustering_suggestions'] = f\"Error: {e}\"\n        try:\n            if not results.get('time_analysis_skipped'): ts_plots=list(results.get('plot_paths',{}).get('time_series',{})); ts_target=results.get('time_analysis_results',{}).get('target_col','N/A'); context=f\"Time series analysis on '{ts_target}'. Plots: {ts_plots}.\"; prompt=f\"Context: [{context}]. Based on visual trends/decomposition, suggest implications or next steps for forecasting/analysis?\"; results['narratives']['time_series_suggestions'] = get_gemini_narrative(prompt, gemini_ready)\n            else: results['narratives']['time_series_suggestions'] = \"N/A.\"\n        except Exception as e: results['narratives']['time_series_suggestions'] = f\"Error: {e}\"\n        try: skew_risk=[k for k,v in skew_data.items() if abs(v)>2]; anomaly_perc=results.get('anomaly_results',{}).get('percentage',0); context=f\"Missing Data: {missing_summary}. Highly Skewed: {skew_risk}. Potential Anomalies: {anomaly_perc:.1f}%. High Cardinality (noise risk): Ticket.\"; results['narratives']['risk_identification'] = get_gemini_narrative(f\"Synthesize data quality risks: [{context}]. Write brief paragraph on main risks (bias from missing data, impact of skew/outliers/anomalies, noisy features).\", gemini_ready); print(\"Generated Risk Identification narrative.\")\n        except Exception as e: results['narratives']['risk_identification'] = f\"Error: {e}\"\n\n        # Print summary\n        print(\"\\nGenerated Narratives & Suggestions Summary:\"); [print(f\" - {k}: {'Generated' if isinstance(v,str) and len(v)>10 and 'N/A' not in v and 'Error' not in v and 'failed' not in v.lower() and 'skipped' not in v.lower() else v[:60]+'...'}\") for k,v in results.get('narratives',{}).items()];\n        return results # Return updated results\n\n    # --- Main logic for this cell ---\n    try:\n        # Run the LLM generation function\n        analysis_results = run_llm_generation(df, analysis_results, gemini_ready)\n\n        # --- Save Final Results (including narratives) ---\n        try:\n            with open(RESULTS_FILE, 'wb') as f:\n                pickle.dump(analysis_results, f)\n            print(f\"\\nFinal results with narratives saved to {RESULTS_FILE}\")\n            print(\"\\n--- LLM Generation Complete ---\")\n            print(\"Proceed to next cell (HTML Generation).\")\n        except Exception as e:\n            print(f\"ERROR: Failed to save final results after LLM generation: {e}\")\n\n    except Exception as e:\n        print(f\"ERROR during LLM Generation processing: {e}\")\nelse:\n     print(\"Cannot run LLM Generation: analysis_results failed to load or df is missing.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:10:07.255576Z","iopub.execute_input":"2025-04-11T18:10:07.256319Z","iopub.status.idle":"2025-04-11T18:10:21.811416Z","shell.execute_reply.started":"2025-04-11T18:10:07.256264Z","shell.execute_reply":"2025-04-11T18:10:21.810473Z"}},"outputs":[{"name":"stdout","text":"--- Running LLM Narrative & Suggestion Generation ---\nLoaded previous results from /kaggle/working/output/analysis_results.pkl\nGemini Readiness Check: True\n\n--- Running LLM Narrative & Suggestion Generation ---\nGenerating main narratives & suggestions...\n - Generating Overview Narrative...\n - Generating Statistics Narrative...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"name":"stdout","text":" - Generating Nuances Narrative...\n - Generating Visualizations Narrative...\n - Generating Correlation Narrative...\n - Generating Anomaly Description Narrative...\n - Generating Clustering Description Narrative...\n - Generating Domain Insights Narrative...\n - Generating Time Series Narrative...\n\nGenerating suggestions & risk ID...\nGenerated Risk Identification narrative.\n\nGenerated Narratives & Suggestions Summary:\n - overview: Generated\n - statistics: Generated\n - nuances: Generated\n - visualizations: Generated\n - correlation: Generated\n - anomaly_description: Generated\n - clustering_description: Clustering analysis skipped....\n - domain_insights: Generated\n - time_series_description: Generated\n - nuances_suggestions: Generated\n - viz_suggestions: Generated\n - corr_suggestions: Generated\n - clustering_suggestions: N/A....\n - risk_identification: Generated\n - time_series_suggestions: N/A....\n\nFinal results with narratives saved to /kaggle/working/output/analysis_results.pkl\n\n--- LLM Generation Complete ---\nProceed to next cell (HTML Generation).\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Cell 8: HTML & PDF Report Generation (Select Table Columns & Add Note)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt # Still potentially needed by helpers indirectly\nimport seaborn as sns # Still potentially needed by helpers indirectly\nimport os\nimport io\nimport base64\nimport pickle\nimport gc\n# WeasyPrint check needed for completeness\ntry: from weasyprint import HTML as WPHTML, CSS; WEASYPRINT_AVAILABLE = True\nexcept ImportError: WEASYPRINT_AVAILABLE = False # Set flag based on availability\nfrom IPython.display import HTML, display, FileLink\n\nprint(\"--- Running Final Report Generation (Select Table Columns) ---\")\n\n# --- Configuration ---\nOUTPUT_DIR = '/kaggle/working/output'\nRESULTS_FILE = os.path.join(OUTPUT_DIR, 'analysis_results.pkl')\nHTML_REPORT_PATH = os.path.join(OUTPUT_DIR, 'analysis_report_selected_cols.html') # New HTML name\nPDF_REPORT_PATH = os.path.join(OUTPUT_DIR, 'analysis_report_selected_cols.pdf')  # New PDF name\n\n# --- Load Final Results ---\nanalysis_results = None\nif os.path.exists(RESULTS_FILE):\n    try:\n        with open(RESULTS_FILE, 'rb') as f:\n            analysis_results = pickle.load(f)\n        print(f\"Loaded final results from {RESULTS_FILE}\")\n    except Exception as e:\n        print(f\"ERROR: Failed to load results file '{RESULTS_FILE}': {e}. Cannot proceed.\")\n        analysis_results = None # Ensure it's None if load fails\nelse:\n    print(f\"ERROR: Results file '{RESULTS_FILE}' not found. Run previous cells first.\")\n    analysis_results = None # Ensure it's None if file not found\n\n# --- Check if results loaded ---\nif analysis_results:\n\n    # --- Redefine HTML Generation Function and Helpers ---\n    def df_to_html(df_in):\n        # Helper to convert DataFrame to HTML\n        if df_in is None: return \"<p>N/A</p>\"\n        try:\n            # Make a copy to avoid modifying the original DataFrame in analysis_results\n            df_display = df_in.copy()\n            # Convert any non-string columns needed for display back to string if necessary\n            # (e.g., if dtypes were changed) - usually to_html handles this.\n            return df_display.to_html(escape=False, na_rep='-', justify='left', classes='dataframe', border=1)\n        except Exception as e: print(f\"WARN: df_to_html failed: {e}\"); return \"<p>Table display error</p>\"\n\n    def format_missing_html(missing_series, total_rows):\n        # Helper to format missing values list\n        if missing_series is None or missing_series.empty: return \"<p>No missing values detected.</p>\"\n        lines=[\"<ul>\"]+[f\"<li><b>{i}:</b> {v} ({((v/total_rows)*100):.1f}%)</li>\" for i,v in missing_series.items()]+[\"</ul>\"]; return \"\\n\".join(lines)\n\n    def format_plot_html(plot_path, alt_text=\"Plot\"):\n        # Helper to embed plots using Base64\n        if plot_path and os.path.exists(plot_path):\n            try:\n                with open(plot_path, \"rb\") as f: encoded = base64.b64encode(f.read()).decode('utf-8')\n                fmt = os.path.splitext(plot_path)[1][1:].lower().replace('jpg','jpeg')\n                return f'<img src=\"data:image/{fmt};base64,{encoded}\" alt=\"{alt_text}\" style=\"max-width:80%; width: 100%; height:auto;display:block;margin:10px auto;border:1px solid #eee;\">'\n            except Exception as e: print(f\"WARN: Base64 encoding failed for {plot_path}: {e}\"); return f\"<p><i>ERROR encoding plot: {os.path.basename(plot_path)}</i></p>\"\n        else: return f\"<p><i>Plot file not found: {os.path.basename(plot_path) if plot_path else alt_text}.</i></p>\"\n\n    # --- generate_html_report MODIFIED ---\n    def generate_html_report(results, out_dir, report_path):\n        print(\"\\n--- Running Dynamic HTML Report Generation Logic (Selected Columns) ---\")\n        # Define which columns are generally useful for direct display in tables\n        # Omit 'Name', 'Ticket', 'Cabin' as they are wide or mostly empty\n        COLS_TO_DISPLAY_IN_TABLE = ['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n\n        css_styles=results.get('css_styles', \"\"\"\n            body{font-family:sans-serif;margin:20px;line-height:1.5;background-color:#fdfdfd;}\n            h1{color:#2c3e50;border-bottom:2px solid #3498db;padding-bottom:10px;}\n            h2{color:#3498db;border-bottom:1px solid #eee;padding-bottom:5px;margin-top:35px;}\n            h3{color:#555;margin-top:25px;font-size:1.1em;} h4{color:#777;margin-top:20px;font-size:1.0em;font-style:italic;}\n            p{margin-bottom:10px;}\n            /* Make table scrollable if needed, but prioritize fitting */\n            div.table-container { max-width: 100%; overflow-x: auto; margin: 20px 0; }\n            table.dataframe{border-collapse:collapse; width: auto; /* Let table size itself */ margin: 0; /* Remove margin from table itself */ font-size:0.8em; border:1px solid #ccc;}\n            table.dataframe th, table.dataframe td{border:1px solid #ddd; padding: 5px 7px; text-align: left; vertical-align: top; white-space: nowrap; /* Prevent wrapping initially */}\n            /* Allow specific problematic columns like Name (if included) to wrap */\n            /* table.dataframe td:nth-child(4), table.dataframe th:nth-child(4) { white-space: normal; word-wrap: break-word; } */\n            table.dataframe th{background-color:#f0f5f9;font-weight:bold;} table.dataframe tbody tr:nth-child(even){background-color:#f9f9f9;}\n            img{max-width:85%;height:auto;display:block;margin:20px auto;border:1px solid #ddd;padding:3px;background-color:white;}\n            .suggestion{background-color:#f0f8ff;border-left:5px solid #79bdee;padding:10px 15px;margin:20px 0;font-style:normal;}\n            .suggestion p{margin:5px 0;} ul{margin-left:20px;padding-left:10px;} li{margin-bottom:6px;}\n            section{margin-bottom:30px;padding-bottom:20px;border-bottom:1px dashed #ccc;} section:last-of-type{border-bottom:none;}\n            .omitted-note { font-size: 0.8em; color: #666; margin-top: 5px; }\n        \"\"\") # Added table-container and omitted-note styles\n        narratives=results.get('narratives', {});\n\n        html_parts=[f\"\"\"<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"UTF-8\"><title>Automated Analysis Report</title><style>{css_styles}</style></head><body>\n                     <h1>Automated Analysis Report</h1><p>Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\"\"\"]\n        section_counter=1\n        def add_section(title, content_html):\n            nonlocal section_counter; html_parts.append(f\"<section><h2>{section_counter}. {title}</h2>\"); html_parts.append(content_html); html_parts.append(\"</section>\"); section_counter += 1\n\n        # --- Define function to handle table display and omitted columns note ---\n        def create_table_display_html(df_full, df_dtypes=None):\n            \"\"\" Creates HTML for a table, displaying subset of columns and noting omitted ones.\"\"\"\n            if df_full is None: return \"<p>N/A</p>\"\n\n            # Find which columns from COLS_TO_DISPLAY_IN_TABLE exist in the df\n            cols_to_show = [col for col in COLS_TO_DISPLAY_IN_TABLE if col in df_full.columns]\n            df_display = df_full[cols_to_show]\n\n            table_html = df_to_html(df_display)\n            omitted_cols = [col for col in df_full.columns if col not in cols_to_show]\n            note_html = \"\"\n            if omitted_cols:\n                 omitted_info = []\n                 if df_dtypes is not None: # Get types if available\n                      for col in omitted_cols:\n                           omitted_info.append(f\"{col} [{df_dtypes.get(col, 'N/A')}]\")\n                 else: # Otherwise just list names\n                      omitted_info = omitted_cols\n                 note_html = f\"<p class='omitted-note'><i>(Columns not displayed: {', '.join(omitted_info)})</i></p>\"\n\n            # Wrap table in a scrollable div\n            return f\"<div class='table-container'>{table_html}</div>{note_html}\"\n\n        # Get original dtypes for reference\n        original_dtypes = df.dtypes if 'df' in locals() and df is not None else None\n\n        # --- Define sections structure ---\n        sections_info=[\n            ('Overview', lambda r: True, lambda r, n: f\"<p>{n.get('overview','N/A')}</p><h3>Head (First {len(r.get('head',[]))} Rows):</h3>{create_table_display_html(r.get('head'), original_dtypes)}<h3>Tail (Last {len(r.get('tail',[]))} Rows):</h3>{create_table_display_html(r.get('tail'), original_dtypes)}\"),\n            ('Statistics', lambda r: True, lambda r, n: f\"<p>{n.get('statistics','N/A')}</p><h3>Summary Statistics:</h3>{create_table_display_html(r.get('summary_stats'))}\"), # Keep describe() full for now, might fit\n            ('Data Nuances', lambda r: True, lambda r, n: f\"<p>{n.get('nuances','N/A')}</p><h3>Missing Values:</h3>{format_missing_html(r.get('missing_values'), r.get('shape',(0,0))[0])}<h4>Potential Implications & Next Steps:</h4><div class='suggestion'><p>{n.get('nuances_suggestions','N/A')}</p></div>\"),\n            ('Basic Visualizations', lambda r: True, lambda r, n: (lambda hp, cp: f\"<p>{n.get('visualizations','N/A')}</p>\" + (f\"<h3>Histograms:</h3>{''.join([format_plot_html(p,f'Hist {c}') for c,p in hp.items()])}\" if hp else \"<p><i>No histograms generated/found.</i></p>\") + (f\"<h3>Count Plots:</h3>{''.join([format_plot_html(p,f'Count {c}') for c,p in cp.items()])}\" if cp else \"<p><i>No count plots generated/found.</i></p>\") + f\"<h4>Potential Implications & Considerations:</h4><div class='suggestion'><p>{n.get('viz_suggestions','N/A')}</p></div>\")(r.get('plot_paths',{}).get('histograms',{}), r.get('plot_paths',{}).get('count_plots',{}))),\n            ('Correlation Analysis', 'correlation_skipped', lambda r, n: (lambda cp: f\"<p>{n.get('correlation','N/A')}</p><h3>Correlation Heatmap:</h3>{format_plot_html(r.get('plot_paths',{}).get('heatmap'),'Corr Heatmap')}<h3>Highly Correlated Pairs (> 0.4):</h3>{'<ul>'+''.join([f'<li><b>{p[0]}</b>: {p[1]:.3f}</li>' for p in cp])+'</ul>' if cp else '<p>None above threshold (0.4).</p>'}<h4>Potential Implications & Further Exploration:</h4><div class='suggestion'><p>{n.get('corr_suggestions','N/A')}</p></div>\")(r.get('highly_correlated_pairs',[]))),\n            ('Anomaly Detection', 'anomaly_skipped', lambda r, n: f\"<p>{n.get('anomaly_description','N/A')}</p><ul><li>Features Analyzed: {r.get('anomaly_results',{}).get('features_used',['N/A'])}</li><li>Potential Anomalies Found: {r.get('anomaly_results',{}).get('count','N/A')} ({r.get('anomaly_results',{}).get('percentage','N/A'):.2f}%)</li></ul>\"),\n            ('Clustering Exploration', 'clustering_skipped', lambda r, n: f\"<p>{n.get('clustering_description','N/A')}</p><h3>Cluster Characteristics (K={r.get('clustering_results',{}).get('n_clusters','N/A')}):</h3>{df_to_html(r.get('clustering_results',{}).get('summary_stats'))}<h3>Cluster Visualization (PCA):</h3>{format_plot_html(r.get('plot_paths',{}).get('clustering_pca'),'Cluster PCA')}<h4>Interpretation & Next Steps:</h4><div class='suggestion'><p>{n.get('clustering_suggestions','N/A')}</p></div>\"), # Cluster summary table might also be wide\n            ('Risk Identification Summary', None, lambda r, n: f\"<div class='suggestion'><p>{n.get('risk_identification','N/A')}</p></div>\"),\n            ('Domain Insights (Speculative)', None, lambda r, n: f\"<div class='suggestion'><p>{n.get('domain_insights','N/A')}</p></div>\"),\n            ('Time Series Analysis', 'time_analysis_skipped', lambda r, n: (f\"<p>{n.get('time_series_description','N/A')}</p>\" + (lambda tps: (\"<h3>Plots:</h3>\"+(''.join([format_plot_html(p, f'{k} Plot') for k,p in tps.items()]))) if tps else \"\")(r.get('plot_paths',{}).get('time_series',{})) + f\"<h4>Implications & Further Analysis:</h4><div class='suggestion'><p>{n.get('time_series_suggestions','N/A')}</p></div>\")), # Removed extra parenthesis again\n            (\"Interactive Visualizations\", None, lambda r,n: \"<i>Module not yet implemented.</i>\"),\n            (\"What-If Scenarios\", None, lambda r,n: \"<i>Analysis skipped (requires specific modeling choices).</i>\"),\n            (\"Multi-Dataset Comparisons\", None, lambda r,n: \"<i>Analysis skipped (requires multiple input datasets).</i>\"),\n            (\"Trend Analysis\", None, lambda r,n: \"<i>Module not yet implemented (often part of Time Series).</i>\"),\n        ]\n\n        # Loop through defined sections and add if not skipped\n        for title, skip_key, content_func in sections_info:\n            is_skipped = results.get(skip_key, False) if skip_key else False\n            if skip_key and is_skipped: # If a skip key exists and is True\n                 reason = results.get(f\"{skip_key.replace('_skipped','')}_reason\", \"Analysis skipped or not applicable.\")\n                 add_section(title, f\"<p><i>{reason}</i></p>\")\n            else: # Otherwise, generate the content\n                 add_section(title, content_func(results, narratives))\n\n        html_parts.append(\"</body></html>\"); html_content = \"\\n\".join(html_parts)\n\n        # Write HTML File\n        try:\n            with open(report_path, 'w', encoding='utf-8') as f: f.write(html_content)\n            print(f\"\\nFinal HTML report generated: {report_path}\\nLink: {os.path.join('/kaggle/working/output', os.path.basename(report_path))}\")\n        except Exception as e: print(f\"\\nError writing HTML report: {e}\"); html_content = None\n        print(\"\\n--- Dynamic HTML Report Generation Complete ---\");\n        return html_content # Return HTML content string\n\n    # --- Redefine PDF Generation Function ---\n    def create_pdf_from_html(html_string, pdf_path):\n        print(\"\\n--- Running PDF Generation ---\")\n        if not WEASYPRINT_AVAILABLE: print(\"Skipping PDF Generation: WeasyPrint not available.\"); return False\n        if not html_string: print(\"Skipping PDF Generation: HTML content is empty.\"); return False\n        try:\n            print(f\"Attempting to write PDF to: {pdf_path}\")\n            WPHTML(string=html_string).write_pdf(pdf_path)\n            print(f\"PDF report generated successfully: {pdf_path}\")\n            print(f\"Download Link (Kaggle):\")\n            display(FileLink(pdf_path))\n            return True\n        except Exception as e: print(f\"\\nERROR during PDF Generation: {e}\\nCheck WeasyPrint dependencies.\"); return False\n\n    # --- Main logic for this cell ---\n    html_content_output = None\n    pdf_generated_output = False\n    try:\n        # Generate HTML report content using the MODIFIED function\n        html_content_output = generate_html_report(analysis_results, OUTPUT_DIR, HTML_REPORT_PATH)\n\n        # Generate PDF report from HTML content\n        if html_content_output:\n            pdf_generated_output = create_pdf_from_html(html_content_output, PDF_REPORT_PATH)\n\n        print(\"\\n--- Report Generation Complete ---\")\n        if pdf_generated_output: print(\"Both HTML and PDF reports generated.\")\n        elif html_content_output: print(\"HTML report generated; PDF failed/skipped.\")\n        else: print(\"HTML report generation failed.\")\n\n    except Exception as e:\n        print(f\"ERROR during Report Generation processing: {e}\")\n\nelse:\n     print(\"Cannot run Report Generation: analysis_results failed to load.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:10:35.769666Z","iopub.execute_input":"2025-04-11T18:10:35.770109Z","iopub.status.idle":"2025-04-11T18:10:35.831078Z","shell.execute_reply.started":"2025-04-11T18:10:35.770070Z","shell.execute_reply":"2025-04-11T18:10:35.829943Z"}},"outputs":[{"name":"stdout","text":"--- Running Final Report Generation (Select Table Columns) ---\nLoaded final results from /kaggle/working/output/analysis_results.pkl\n\n--- Running Dynamic HTML Report Generation Logic (Selected Columns) ---\n\nFinal HTML report generated: /kaggle/working/output/analysis_report_selected_cols.html\nLink: /kaggle/working/output/analysis_report_selected_cols.html\n\n--- Dynamic HTML Report Generation Complete ---\n\n--- Running PDF Generation ---\nSkipping PDF Generation: WeasyPrint not available.\n\n--- Report Generation Complete ---\nHTML report generated; PDF failed/skipped.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Cell 8: HTML & PDF Report Generation (Split Wide Head/Tail Tables)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt # Still potentially needed by helpers indirectly\nimport seaborn as sns # Still potentially needed by helpers indirectly\nimport os\nimport io\nimport base64\nimport pickle\nimport gc\n# WeasyPrint check needed for completeness\ntry: from weasyprint import HTML as WPHTML, CSS; WEASYPRINT_AVAILABLE = True\nexcept ImportError: WEASYPRINT_AVAILABLE = False # Set flag based on availability\nfrom IPython.display import HTML, display, FileLink\n\nprint(\"--- Running Final Report Generation (Split Tables) ---\")\n\n# --- Configuration ---\nOUTPUT_DIR = '/kaggle/working/output'\nRESULTS_FILE = os.path.join(OUTPUT_DIR, 'analysis_results.pkl')\n# Use new filenames for this version\nHTML_REPORT_PATH = os.path.join(OUTPUT_DIR, 'analysis_report_split_tables.html')\nPDF_REPORT_PATH = os.path.join(OUTPUT_DIR, 'analysis_report_split_tables.pdf')\n\n# --- Load Final Results ---\nanalysis_results = None\nif os.path.exists(RESULTS_FILE):\n    try:\n        with open(RESULTS_FILE, 'rb') as f:\n            analysis_results = pickle.load(f)\n        print(f\"Loaded final results from {RESULTS_FILE}\")\n    except Exception as e:\n        print(f\"ERROR: Failed to load results file '{RESULTS_FILE}': {e}. Cannot proceed.\")\n        analysis_results = None\nelse:\n    print(f\"ERROR: Results file '{RESULTS_FILE}' not found. Run previous cells first.\")\n    analysis_results = None\n\n# --- Check if results loaded ---\nif analysis_results:\n\n    # --- Redefine HTML Generation Function and Helpers ---\n    def df_to_html(df_in):\n        # Helper to convert DataFrame to HTML\n        if df_in is None: return \"<p>N/A</p>\"\n        try:\n            df_display = df_in.copy()\n            return df_display.to_html(escape=False, na_rep='-', justify='left', classes='dataframe', border=1)\n        except Exception as e: print(f\"WARN: df_to_html failed: {e}\"); return \"<p>Table display error</p>\"\n\n    def format_missing_html(missing_series, total_rows):\n        # Helper to format missing values list\n        if missing_series is None or missing_series.empty: return \"<p>No missing values detected.</p>\"\n        lines=[\"<ul>\"]+[f\"<li><b>{i}:</b> {v} ({((v/total_rows)*100):.1f}%)</li>\" for i,v in missing_series.items()]+[\"</ul>\"]; return \"\\n\".join(lines)\n\n    def format_plot_html(plot_path, alt_text=\"Plot\"):\n        # Helper to embed plots using Base64\n        if plot_path and os.path.exists(plot_path):\n            try:\n                with open(plot_path, \"rb\") as f: encoded = base64.b64encode(f.read()).decode('utf-8')\n                fmt = os.path.splitext(plot_path)[1][1:].lower().replace('jpg','jpeg')\n                return f'<img src=\"data:image/{fmt};base64,{encoded}\" alt=\"{alt_text}\" style=\"max-width:80%; width: auto; height:auto;display:block;margin:10px auto;border:1px solid #eee;\">' # Adjusted style slightly\n            except Exception as e: print(f\"WARN: Base64 encoding failed for {plot_path}: {e}\"); return f\"<p><i>ERROR encoding plot: {os.path.basename(plot_path)}</i></p>\"\n        else: return f\"<p><i>Plot file not found: {os.path.basename(plot_path) if plot_path else alt_text}.</i></p>\"\n\n    # --- UPDATED: Helper function to split wide tables ---\n    def create_split_table_html(df_full, chunk_size=7):\n        \"\"\" Creates HTML by splitting a wide DataFrame into chunks of columns. \"\"\"\n        if df_full is None: return \"<p>N/A</p>\"\n        num_cols = df_full.shape[1]\n        all_html = [\"<div class='table-container'>\"] # Use container for potential styling/scroll\n        if num_cols <= chunk_size:\n            # Table is narrow enough, display as is\n            all_html.append(df_to_html(df_full))\n        else:\n            # Split into chunks\n            for i in range(0, num_cols, chunk_size):\n                df_chunk = df_full.iloc[:, i:min(i + chunk_size, num_cols)]\n                if i > 0: all_html.append(\"<br>\") # Add space between table chunks\n                all_html.append(f\"<p><i>(Columns {i+1}-{min(i + chunk_size, num_cols)})</i></p>\")\n                all_html.append(df_to_html(df_chunk))\n        all_html.append(\"</div>\")\n        return \"\\n\".join(all_html)\n\n    # --- generate_html_report MODIFIED to use create_split_table_html ---\n    def generate_html_report(results, out_dir, report_path):\n        print(\"\\n--- Running Dynamic HTML Report Generation Logic (Split Tables) ---\")\n        # Define CSS (adjusted table CSS slightly)\n        css_styles=results.get('css_styles', \"\"\"\n            body{font-family:sans-serif;margin:20px;line-height:1.5;background-color:#fdfdfd;}\n            h1{color:#2c3e50;border-bottom:2px solid #3498db;padding-bottom:10px;}\n            h2{color:#3498db;border-bottom:1px solid #eee;padding-bottom:5px;margin-top:35px;}\n            h3{color:#555;margin-top:25px;font-size:1.1em;} h4{color:#777;margin-top:20px;font-size:1.0em;font-style:italic;}\n            p{margin-bottom:10px;}\n            div.table-container { max-width: 100%; overflow-x: auto; margin-bottom: 15px; } /* Add scroll for HTML */\n            table.dataframe{border-collapse:collapse; width: auto; margin: 5px 0; font-size:0.8em; border:1px solid #ccc;} /* Let table size itself */\n            table.dataframe th, table.dataframe td{border:1px solid #ddd; padding: 5px 7px; text-align: left; vertical-align: top; white-space: nowrap; /* Prevent wrapping */}\n            table.dataframe th{background-color:#f0f5f9;font-weight:bold;} table.dataframe tbody tr:nth-child(even){background-color:#f9f9f9;}\n            img{max-width:85%;height:auto;display:block;margin:20px auto;border:1px solid #ddd;padding:3px;background-color:white;}\n            .suggestion{background-color:#f0f8ff;border-left:5px solid #79bdee;padding:10px 15px;margin:20px 0;font-style:normal;}\n            .suggestion p{margin:5px 0;} ul{margin-left:20px;padding-left:10px;} li{margin-bottom:6px;}\n            section{margin-bottom:30px;padding-bottom:20px;border-bottom:1px dashed #ccc;} section:last-of-type{border-bottom:none;}\n        \"\"\")\n        narratives=results.get('narratives', {});\n\n        html_parts=[f\"\"\"<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"UTF-8\"><title>Automated Analysis Report</title><style>{css_styles}</style></head><body>\n                     <h1>Automated Analysis Report</h1><p>Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\"\"\"]\n        section_counter=1\n        def add_section(title, content_html):\n            nonlocal section_counter; html_parts.append(f\"<section><h2>{section_counter}. {title}</h2>\"); html_parts.append(content_html); html_parts.append(\"</section>\"); section_counter += 1\n\n        # Define sections structure using the new table split function for head/tail\n        # Keep describe() as is for now, it might fit better.\n        sections_info=[\n            ('Overview', lambda r: True, lambda r, n: f\"<p>{n.get('overview','N/A')}</p><h3>Head (First {len(r.get('head',[]))} Rows):</h3>{create_split_table_html(r.get('head'))}<h3>Tail (Last {len(r.get('tail',[]))} Rows):</h3>{create_split_table_html(r.get('tail'))}\"), # Use split table\n            ('Statistics', lambda r: True, lambda r, n: f\"<p>{n.get('statistics','N/A')}</p><h3>Summary Statistics:</h3><div class='table-container'>{df_to_html(r.get('summary_stats'))}</div>\"), # Keep describe() as single table but in scrollable div\n            ('Data Nuances', lambda r: True, lambda r, n: f\"<p>{n.get('nuances','N/A')}</p><h3>Missing Values:</h3>{format_missing_html(r.get('missing_values'), r.get('shape',(0,0))[0])}<h4>Potential Implications & Next Steps:</h4><div class='suggestion'><p>{n.get('nuances_suggestions','N/A')}</p></div>\"),\n            ('Basic Visualizations', lambda r: True, lambda r, n: (lambda hp, cp: f\"<p>{n.get('visualizations','N/A')}</p>\" + (f\"<h3>Histograms:</h3>{''.join([format_plot_html(p,f'Hist {c}') for c,p in hp.items()])}\" if hp else \"<p><i>No histograms generated/found.</i></p>\") + (f\"<h3>Count Plots:</h3>{''.join([format_plot_html(p,f'Count {c}') for c,p in cp.items()])}\" if cp else \"<p><i>No count plots generated/found.</i></p>\") + f\"<h4>Potential Implications & Considerations:</h4><div class='suggestion'><p>{n.get('viz_suggestions','N/A')}</p></div>\")(r.get('plot_paths',{}).get('histograms',{}), r.get('plot_paths',{}).get('count_plots',{}))),\n            ('Correlation Analysis', 'correlation_skipped', lambda r, n: (lambda cp: f\"<p>{n.get('correlation','N/A')}</p><h3>Correlation Heatmap:</h3>{format_plot_html(r.get('plot_paths',{}).get('heatmap'),'Corr Heatmap')}<h3>Highly Correlated Pairs (> 0.4):</h3>{'<ul>'+''.join([f'<li><b>{p[0]}</b>: {p[1]:.3f}</li>' for p in cp])+'</ul>' if cp else '<p>None above threshold (0.4).</p>'}<h4>Potential Implications & Further Exploration:</h4><div class='suggestion'><p>{n.get('corr_suggestions','N/A')}</p></div>\")(r.get('highly_correlated_pairs',[]))),\n            ('Anomaly Detection', 'anomaly_skipped', lambda r, n: f\"<p>{n.get('anomaly_description','N/A')}</p><ul><li>Features Analyzed: {r.get('anomaly_results',{}).get('features_used',['N/A'])}</li><li>Potential Anomalies Found: {r.get('anomaly_results',{}).get('count','N/A')} ({r.get('anomaly_results',{}).get('percentage','N/A'):.2f}%)</li></ul>\"),\n            ('Clustering Exploration', 'clustering_skipped', lambda r, n: f\"<p>{n.get('clustering_description','N/A')}</p><h3>Cluster Characteristics (K={r.get('clustering_results',{}).get('n_clusters','N/A')}):</h3><div class='table-container'>{df_to_html(r.get('clustering_results',{}).get('summary_stats'))}</div><h3>Cluster Visualization (PCA):</h3>{format_plot_html(r.get('plot_paths',{}).get('clustering_pca'),'Cluster PCA')}<h4>Interpretation & Next Steps:</h4><div class='suggestion'><p>{n.get('clustering_suggestions','N/A')}</p></div>\"), # Added scroll div for cluster summary too\n            ('Risk Identification Summary', None, lambda r, n: f\"<div class='suggestion'><p>{n.get('risk_identification','N/A')}</p></div>\"),\n            ('Domain Insights (Speculative)', None, lambda r, n: f\"<div class='suggestion'><p>{n.get('domain_insights','N/A')}</p></div>\"),\n            ('Time Series Analysis', 'time_analysis_skipped', lambda r, n: (f\"<p>{n.get('time_series_description','N/A')}</p>\" + (lambda tps: (\"<h3>Plots:</h3>\"+(''.join([format_plot_html(p, f'{k} Plot') for k,p in tps.items()]))) if tps else \"\")(r.get('plot_paths',{}).get('time_series',{})) + f\"<h4>Implications & Further Analysis:</h4><div class='suggestion'><p>{n.get('time_series_suggestions','N/A')}</p></div>\")),\n            (\"Interactive Visualizations\", None, lambda r,n: \"<i>Module not yet implemented.</i>\"),\n            (\"What-If Scenarios\", None, lambda r,n: \"<i>Analysis skipped (requires specific modeling choices).</i>\"),\n            (\"Multi-Dataset Comparisons\", None, lambda r,n: \"<i>Analysis skipped (requires multiple input datasets).</i>\"),\n            (\"Trend Analysis\", None, lambda r,n: \"<i>Module not yet implemented (often part of Time Series).</i>\"),\n        ]\n\n        # Loop through defined sections and add if not skipped\n        for title, skip_key, content_func in sections_info:\n            is_skipped = results.get(skip_key, False) if skip_key else False\n            if skip_key and is_skipped:\n                 reason = results.get(f\"{skip_key.replace('_skipped','')}_reason\", \"Analysis skipped or not applicable.\")\n                 add_section(title, f\"<p><i>{reason}</i></p>\")\n            else:\n                 add_section(title, content_func(results, narratives))\n\n        html_parts.append(\"</body></html>\"); html_content = \"\\n\".join(html_parts)\n\n        # Write HTML File\n        try:\n            with open(report_path, 'w', encoding='utf-8') as f: f.write(html_content)\n            print(f\"\\nFinal HTML report generated: {report_path}\\nLink: {os.path.join('/kaggle/working/output', os.path.basename(report_path))}\")\n        except Exception as e: print(f\"\\nError writing HTML report: {e}\"); html_content = None\n        print(\"\\n--- Dynamic HTML Report Generation Complete ---\");\n        return html_content # Return HTML content string\n\n    # --- Redefine PDF Generation Function ---\n    def create_pdf_from_html(html_string, pdf_path):\n        print(\"\\n--- Running PDF Generation ---\")\n        if not WEASYPRINT_AVAILABLE: print(\"Skipping PDF Generation: WeasyPrint not available.\"); return False\n        if not html_string: print(\"Skipping PDF Generation: HTML content is empty.\"); return False\n        try:\n            print(f\"Attempting to write PDF to: {pdf_path}\")\n            # Add base_url for relative paths if needed, though Base64 shouldn't need it\n            # base_url = f\"file://{OUTPUT_DIR}/\" # Example if using relative file paths for images\n            WPHTML(string=html_string).write_pdf(pdf_path)\n            print(f\"PDF report generated successfully: {pdf_path}\")\n            print(f\"Download Link (Kaggle):\")\n            display(FileLink(pdf_path))\n            return True\n        except Exception as e: print(f\"\\nERROR during PDF Generation: {e}\\nCheck WeasyPrint dependencies.\"); return False\n\n    # --- Main logic for this cell ---\n    html_content_output = None\n    pdf_generated_output = False\n    try:\n        # Generate HTML report content using the MODIFIED function\n        html_content_output = generate_html_report(analysis_results, OUTPUT_DIR, HTML_REPORT_PATH)\n\n        # Generate PDF report from HTML content\n        if html_content_output:\n            pdf_generated_output = create_pdf_from_html(html_content_output, PDF_REPORT_PATH)\n\n        print(\"\\n--- Report Generation Complete ---\")\n        if pdf_generated_output: print(\"Both HTML and PDF reports generated.\")\n        elif html_content_output: print(\"HTML report generated; PDF failed/skipped.\")\n        else: print(\"HTML report generation failed.\")\n\n    except Exception as e:\n        print(f\"ERROR during Report Generation processing: {e}\")\n\nelse:\n     print(\"Cannot run Report Generation: analysis_results failed to load.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:40:24.776271Z","iopub.execute_input":"2025-04-11T18:40:24.776639Z","iopub.status.idle":"2025-04-11T18:40:24.839041Z","shell.execute_reply.started":"2025-04-11T18:40:24.776613Z","shell.execute_reply":"2025-04-11T18:40:24.838062Z"}},"outputs":[{"name":"stdout","text":"--- Running Final Report Generation (Split Tables) ---\nLoaded final results from /kaggle/working/output/analysis_results.pkl\n\n--- Running Dynamic HTML Report Generation Logic (Split Tables) ---\n\nFinal HTML report generated: /kaggle/working/output/analysis_report_split_tables.html\nLink: /kaggle/working/output/analysis_report_split_tables.html\n\n--- Dynamic HTML Report Generation Complete ---\n\n--- Running PDF Generation ---\nSkipping PDF Generation: WeasyPrint not available.\n\n--- Report Generation Complete ---\nHTML report generated; PDF failed/skipped.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}